{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification (GRU).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1Q3ZtDDtBPp",
        "colab_type": "text"
      },
      "source": [
        "#Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk9it3H2Xtyw",
        "colab_type": "code",
        "outputId": "56eb7221-3f47-426f-e62c-46d25b015cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"./gdrive/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at ./gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w0okwNVtPDB",
        "colab_type": "text"
      },
      "source": [
        "#Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw_OAcvmf1sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import spacy\n",
        "\n",
        "nlp=spacy.load(\"en\")\n",
        "\n",
        "def tokenizer(sentence):\n",
        "  return [token.text for token in nlp.tokenizer(sentence)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afi0H7oHU_ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import Field\n",
        "\n",
        "TEXT=Field(sequential=True,lower=True,tokenize=tokenizer,init_token=\"<start>\",eos_token=\"<end>\",batch_first=True)\n",
        "LABEL=Field(sequential=False,batch_first=True,unk_token=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP8SOZfaWs0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import TabularDataset\n",
        "\n",
        "root=\"./gdrive/My Drive/Amazon Review Dataset\"\n",
        "fields={\"label\":(\"label\",LABEL),\"sentence\":(\"sentence\",TEXT)}\n",
        "\n",
        "train,val,test=TabularDataset.splits(path=root,train=\"train.json\", validation=\"valid.json\", test=\"test.json\",format=\"json\",fields=fields)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODr7UfxLZG7C",
        "colab_type": "code",
        "outputId": "d48213cb-2f0e-4e7a-fc3a-046ab6136263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "TEXT.build_vocab(train, vectors=\"glove.6B.300d\")               # can specify vocab_size\n",
        "LABEL.build_vocab(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [00:34, 25.2MB/s]                           \n",
            "100%|█████████▉| 399111/400000 [00:38<00:00, 10497.33it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffmDgrcecEDJ",
        "colab_type": "code",
        "outputId": "2b66b3fc-a665-427d-f5dd-7b40952b48da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(len(TEXT.vocab))\n",
        "print(LABEL.vocab.stoi)\n",
        "print(LABEL.vocab.freqs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "58714\n",
            "defaultdict(<function _default_unk_index at 0x7f21aa93d8c8>, {1: 0, 0: 1})\n",
            "Counter({1: 10056, 0: 9908})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smgjECKLcHxp",
        "colab_type": "code",
        "outputId": "f9b830ff-a2d1-4bc4-e779-c4e16afc69b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(TEXT.vocab.stoi[\"<end>\"])\n",
        "print(TEXT.vocab.stoi[\"<pad>\"])\n",
        "print(TEXT.vocab.stoi[\"n't\"])\n",
        "\n",
        "print(TEXT.vocab.itos[55])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "1\n",
            "30\n",
            "has\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eytjoa0Ajei7",
        "colab_type": "code",
        "outputId": "83f188d4-58a4-4828-b50f-6df589c17387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 125253), ('.', 121329), (',', 96666), ('and', 66508), ('i', 62321), ('to', 60863), ('a', 59332), ('it', 51535), ('of', 46838), ('is', 41696), (' ', 41276), ('this', 34363), ('in', 30303), ('that', 27083), ('for', 25881), ('you', 20498), ('with', 19470), ('was', 18007), (\"'s\", 17939), ('on', 17860)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C4Svm7AtuAA",
        "colab_type": "text"
      },
      "source": [
        "##creating data-iterators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7qrgdKceFz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=64\n",
        "\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#device=torch.device(\"cpu\")\n",
        "\n",
        "train_iter, val_iter, test_iter= torchtext.data.BucketIterator.splits( (train,val,test), sort_key=lambda x: len(x.sentence), batch_size=batch_size, device=device)         \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crHMNf-onFrG",
        "colab_type": "code",
        "outputId": "ff63bb38-27e4-4cef-ed24-1954f00737b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrKG3kxYnLnE",
        "colab_type": "code",
        "outputId": "c7092504-8f38-406c-962e-546d6b467064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "for batch in train_iter:\n",
        "  print(batch.label)\n",
        "  print(batch.label.shape)\n",
        "  print(batch.sentence)\n",
        "  print(batch.sentence.shape)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
            "        1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
            "        0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "torch.Size([64])\n",
            "tensor([[   2,  601,   15,  ...,    1,    1,    1],\n",
            "        [   2,    8,  129,  ...,    1,    1,    1],\n",
            "        [   2,   15, 1926,  ...,    1,    1,    1],\n",
            "        ...,\n",
            "        [   2,    8,  152,  ...,    1,    1,    1],\n",
            "        [   2, 9497,   84,  ...,    1,    1,    1],\n",
            "        [   2,    8,  242,  ...,    1,    1,    1]], device='cuda:0')\n",
            "torch.Size([64, 568])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk6TnH9tnVKl",
        "colab_type": "code",
        "outputId": "43006b26-59ef-4169-9e98-eb6548270bd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkVDxaLytmGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOestYK5tm3V",
        "colab_type": "text"
      },
      "source": [
        "## loading pre-trained weight vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnCxWC_W5vqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_matrix=TEXT.vocab.vectors\n",
        "vocab_size, emb_dim= weight_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpaRSfqV8hxw",
        "colab_type": "code",
        "outputId": "810117b3-38c3-464c-9512-a6cf1d90fdb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "print(weight_matrix[58713,:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTb4J4s6rxf4",
        "colab_type": "text"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRNScusN0B7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  \n",
        "  def __init__(self , vocab_size, emb_dim, hidden_dim):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.embedding= nn.Embedding.from_pretrained(weight_matrix)\n",
        "    self.gru = nn.GRU(emb_dim, hidden_dim, num_layers=2, batch_first=True, bidirectional=True)\n",
        "    self.ff1 = nn.Linear(4 * hidden_dim, 128)\n",
        "    self.ff2 = nn.Linear(128,1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    \n",
        "    emb = self.embedding(x)\n",
        "    lstm_out, h = self.gru(emb)\n",
        "    h=h.permute(1,0,2)\n",
        "    f1_out = self.relu(self.ff1(h.reshape(h.shape[0],-1)))\n",
        "    output = self.sigmoid(self.ff2(f1_out))\n",
        "    \n",
        "    \n",
        "    return output.squeeze(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3C-DoyjhRUd",
        "colab_type": "code",
        "outputId": "40af5ae1-a68d-4e86-a129-6289d711f2df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "epochs=40\n",
        "hidden_dim=128\n",
        "\n",
        "model=Classifier(vocab_size, emb_dim, hidden_dim)\n",
        "model.to(device)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (embedding): Embedding(58714, 300)\n",
              "  (gru): GRU(300, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (ff1): Linear(in_features=512, out_features=128, bias=True)\n",
              "  (ff2): Linear(in_features=128, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM8KauHZht5t",
        "colab_type": "code",
        "outputId": "3505a8c3-53cd-4673-decf-73d23fa330c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.BCELoss()\n",
        "criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCELoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMFGIApE44Hy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_accuracy(pred, labels):\n",
        "  \n",
        "  rounded_pred=torch.round(pred)\n",
        "  equal= (rounded_pred==labels.view(*rounded_pred.shape)).float()\n",
        "  accuracy= equal.sum()/len(equal)\n",
        "  \n",
        "  return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVVWBaK4t73Q",
        "colab_type": "text"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UYHQc_qh6nj",
        "colab_type": "code",
        "outputId": "8070571b-770a-4b02-cc84-454447b41814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import math\n",
        "\n",
        "min_val_loss=10000000000000\n",
        "\n",
        "training_acc = []\n",
        "training_losses = []\n",
        "validation_acc = []\n",
        "validation_losses = []\n",
        "\n",
        "\n",
        "for epoch in range(1,epochs+1):\n",
        "  \n",
        "  train_acc = 0\n",
        "  train_loss = 0\n",
        "  val_acc = 0\n",
        "  val_loss = 0\n",
        "  \n",
        "  print(\"Epoch: \",epoch)\n",
        "  \n",
        "  model.train()\n",
        "  \n",
        "  t=0\n",
        "  step=25/len(train_iter)\n",
        "  for batch in train_iter:\n",
        "    t+=1\n",
        "    \n",
        "    \n",
        "    batch.label=batch.label.type(torch.FloatTensor)\n",
        "      \n",
        "    batch.sentence=batch.sentence.to(device)\n",
        "    batch.label=batch.label.to(device)\n",
        "    \n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    predictions = model(batch.sentence)\n",
        "    \n",
        "    loss = criterion(predictions,batch.label)\n",
        "    acc=binary_accuracy(predictions,batch.label)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    train_loss+=loss.item()\n",
        "    train_acc+=acc.item()\n",
        "    \n",
        "    \n",
        "    print('\\r' + f'Training: '\n",
        "                f\"[{'=' * int((t) * step) + ' ' * (24 - int((t) * step))}]\"\n",
        "                f\"({math.ceil((t) * 100 /len(train_iter))} %)\",\n",
        "                end='')\n",
        "  \n",
        "  \n",
        "  train_acc/=len(train_iter)\n",
        "  train_loss/=len(train_iter)\n",
        "  print('\\nTraining Loss: {:.6f} /t Training accuracy: {: .6f}'.format( train_loss,train_acc))\n",
        "  training_acc.append(train_acc)\n",
        "  training_losses.append(train_loss)\n",
        "  \n",
        "  \n",
        "  with torch.no_grad():\n",
        "    \n",
        "    model.eval()\n",
        "    t=0\n",
        "    step=25/len(val_iter)\n",
        "    for val_batch in val_iter:\n",
        "      t+=1\n",
        "      \n",
        "      val_batch.label=val_batch.label.type(torch.FloatTensor)\n",
        "      \n",
        "      val_batch.sentence=val_batch.sentence.to(device)\n",
        "      val_batch.label=val_batch.label.to(device)\n",
        "      \n",
        "      predictions = model(val_batch.sentence)\n",
        "      loss = criterion(predictions,val_batch.label)\n",
        "      acc=binary_accuracy(predictions,val_batch.label)\n",
        "      \n",
        "      \n",
        "      val_loss+=loss.item()\n",
        "      val_acc+=acc.item()\n",
        "      \n",
        "      \n",
        "      \n",
        "      print('\\r' + f'Validation: '\n",
        "                f\"[{'=' * int((t) * step) + ' ' * (24 - int((t) * step))}]\"\n",
        "                f\"({math.ceil((t) * 100 /len(val_iter))} %)\",\n",
        "                end='')\n",
        "      \n",
        "    val_acc/=len(val_iter)\n",
        "    val_loss/=len(val_iter)\n",
        "    print('\\nValidation Loss: {:.6f} /t Validation accuracy: {: .6f}'.format( val_loss,val_acc))\n",
        "    validation_acc.append(val_acc)\n",
        "    validation_losses.append(val_loss)\n",
        "    \n",
        "    if val_loss< min_val_loss:\n",
        "      min_val_loss= val_loss\n",
        "      \n",
        "      print(\"Validation loss reduced to {:.6f}, saving model............\".format(val_loss))\n",
        "      torch.save(model.state_dict(), 'text-model.epoch='+str(epoch)+'.pt')\n",
        "      print()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  1\n",
            "Training: [=                       ](5 %)"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 399111/400000 [00:50<00:00, 10497.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: [=========================](100 %)\n",
            "Training Loss: 0.528513 /t Training accuracy:  0.733480\n",
            "Validation: [=========================](100 %)\n",
            "Validation Loss: 0.419511 /t Validation accuracy:  0.820268\n",
            "Validation loss reduced to 0.419511, saving model............\n",
            "\n",
            "Epoch:  2\n",
            "Training: [=========================](100 %)\n",
            "Training Loss: 0.367409 /t Training accuracy:  0.841877\n",
            "Validation: [=========================](100 %)\n",
            "Validation Loss: 0.344047 /t Validation accuracy:  0.867411\n",
            "Validation loss reduced to 0.344047, saving model............\n",
            "\n",
            "Epoch:  3\n",
            "Training: [=========================](100 %)\n",
            "Training Loss: 0.290215 /t Training accuracy:  0.880335\n",
            "Validation: [=========================](100 %)\n",
            "Validation Loss: 0.299775 /t Validation accuracy:  0.872143\n",
            "Validation loss reduced to 0.299775, saving model............\n",
            "\n",
            "Epoch:  4\n",
            "Training: [=========================](100 %)\n",
            "Training Loss: 0.237038 /t Training accuracy:  0.905746\n",
            "Validation: [=========================](100 %)\n",
            "Validation Loss: 0.273733 /t Validation accuracy:  0.886786\n",
            "Validation loss reduced to 0.273733, saving model............\n",
            "\n",
            "Epoch:  5\n",
            "Training: [=========================](100 %)\n",
            "Training Loss: 0.185080 /t Training accuracy:  0.931140\n",
            "Validation: [=========================](100 %)\n",
            "Validation Loss: 0.309823 /t Validation accuracy:  0.882500\n",
            "Epoch:  6\n",
            "Training: [=========================](100 %)\n",
            "Training Loss: 0.139784 /t Training accuracy:  0.950457\n",
            "Validation: [=========================](100 %)\n",
            "Validation Loss: 0.306687 /t Validation accuracy:  0.887232\n",
            "Epoch:  7\n",
            "Training: [=========================](100 %)\n",
            "Training Loss: 0.098161 /t Training accuracy:  0.967635\n",
            "Validation: [=========================](100 %)\n",
            "Validation Loss: 0.333635 /t Validation accuracy:  0.882679\n",
            "Epoch:  8\n",
            "Training: [=========================](100 %)\n",
            "Training Loss: 0.066282 /t Training accuracy:  0.978806\n",
            "Validation: [=========================](100 %)\n",
            "Validation Loss: 0.375167 /t Validation accuracy:  0.878839\n",
            "Epoch:  9\n",
            "Training: [=========================](100 %)\n",
            "Training Loss: 0.051036 /t Training accuracy:  0.983019\n",
            "Validation: [=========================](100 %)\n",
            "Validation Loss: 0.397410 /t Validation accuracy:  0.884911\n",
            "Epoch:  10\n",
            "Training: [=========================](100 %)\n",
            "Training Loss: 0.039434 /t Training accuracy:  0.986629\n",
            "Validation: [=========================](100 %)\n",
            "Validation Loss: 0.447560 /t Validation accuracy:  0.885536\n",
            "Epoch:  11\n",
            "Training: [=========================](100 %)\n",
            "Training Loss: 0.020484 /t Training accuracy:  0.993490\n",
            "Validation: [=========================](100 %)\n",
            "Validation Loss: 0.669381 /t Validation accuracy:  0.878036\n",
            "Epoch:  12\n",
            "Training: [=========================](100 %)\n",
            "Training Loss: 0.021395 /t Training accuracy:  0.992588\n",
            "Validation: [=========================](100 %)\n",
            "Validation Loss: 0.553328 /t Validation accuracy:  0.885446\n",
            "Epoch:  13\n",
            "Training: [=======                 ](29 %)"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-428ce9d3cecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-86126d00d55c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mf1_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             result = _impl(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 211\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             result = _impl(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXR1N2rS9ukR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "\n",
        "for i in range(1,5):\n",
        "  shutil.copy(\"./text-model.epoch=\"+str(i)+\".pt\",\"./gdrive/My Drive/Amazon Review Dataset/GRU/text-model.epoch=\"+str(i)+\".pt\")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TBKvMCYezCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD9jw3yOcjXR",
        "colab_type": "text"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v4lQa75c6yS",
        "colab_type": "code",
        "outputId": "5994f370-5cf9-4042-a935-ba99a6728b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "state_dict=torch.load(\"./gdrive/My Drive/Amazon Review Dataset/GRU/text-model.epoch=4.pt\")\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GuewhX_dgjS",
        "colab_type": "code",
        "outputId": "c74ccb62-23b1-44c2-c86c-ae7f31f144e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (embedding): Embedding(58714, 300)\n",
              "  (gru): GRU(300, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (ff1): Linear(in_features=512, out_features=128, bias=True)\n",
              "  (ff2): Linear(in_features=128, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6RdpvBLe3aN",
        "colab_type": "code",
        "outputId": "6b2bdc0d-8266-47d4-9f2a-03ccaa9eb5e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "    test_acc =0\n",
        "    test_loss=0\n",
        "    t=0\n",
        "    step=25/len(test_iter)\n",
        "    for test_batch in test_iter:\n",
        "      t+=1\n",
        "      \n",
        "      test_batch.label=test_batch.label.type(torch.FloatTensor)\n",
        "      \n",
        "      test_batch.sentence=test_batch.sentence.to(device)\n",
        "      test_batch.label=test_batch.label.to(device)\n",
        "      \n",
        "      predictions = model(test_batch.sentence)\n",
        "      loss = criterion(predictions,test_batch.label)\n",
        "      acc=binary_accuracy(predictions,test_batch.label)\n",
        "      \n",
        "      \n",
        "      test_loss+=loss.item()\n",
        "      test_acc+=acc.item()\n",
        "      \n",
        "      \n",
        "      \n",
        "      print('\\r' + f'Testing: '\n",
        "                f\"[{'=' * int((t) * step) + ' ' * (24 - int((t) * step))}]\"\n",
        "                f\"({math.ceil((t) * 100 /len(test_iter))} %)\",\n",
        "                end='')\n",
        "      \n",
        "    test_acc/=len(test_iter)\n",
        "    test_loss/=len(test_iter)\n",
        "    print('\\nTest Loss: {:.6f} /t Test accuracy: {: .6f}'.format( test_loss,test_acc))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing: [=========================](100 %)\n",
            "Test Loss: 0.280789 /t Test accuracy:  0.885121\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}